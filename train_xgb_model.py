# -*- coding: utf-8 -*-
"""train_xgb_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13qIM2nZEMMKcnI_jYAVxERBVp46Fgi0w
"""

import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report

# Load dataset
df = pd.read_csv("predictive_maintenance.csv")

# Drop unnecessary columns
df.drop(columns=["UDI", "Product ID"], inplace=True)

# Encode categorical variables
le_type = LabelEncoder()
df["Type"] = le_type.fit_transform(df["Type"])
le_failure = LabelEncoder()
df["Failure Type"] = le_failure.fit_transform(df["Failure Type"])

# Define features and target
X = df.drop(columns=["Failure Type", "Target"])
y = df["Failure Type"]

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost model
xgb_model = xgb.XGBClassifier(objective="multi:softmax", num_class=len(le_failure.classes_), eval_metric="mlogloss")
xgb_model.fit(X_train, y_train)

# Evaluate model
y_pred = xgb_model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=le_failure.classes_))

# Save model and encoders
joblib.dump(xgb_model, "xgb_model.pkl")
joblib.dump(le_type, "le_type.pkl")
joblib.dump(le_failure, "le_failure.pkl")

print("Model training complete. Model saved as 'xgb_model.pkl'")